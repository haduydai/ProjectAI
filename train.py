import os
import tensorflow as tf
from tensorflow.keras import layers, models
from data_loader import DidaLoader 

# --- C·∫§U H√åNH T·ªêI ∆ØU ---
# Tr·ªè v√†o th∆∞ m·ª•c ch·ª©a dataset
DATASET_PATH = os.path.join('dataset', '250000', '250000_Final')

# 1. Gi·ªõi h·∫°n s·ªë l∆∞·ª£ng ·∫£nh (ho·∫∑c None n·∫øu m√°y m·∫°nh)
MAX_IMAGES = 50000  

# 2. TƒÉng Batch Size (M·∫∑c ƒë·ªãnh 32 -> TƒÉng l√™n 128 ho·∫∑c 256)
# S·ªë c√†ng to train c√†ng nhanh, nh∆∞ng t·ªën VRAM. N·∫øu l·ªói OOM th√¨ gi·∫£m xu·ªëng 64.
BATCH_SIZE = 128 

# 3. S·ªë v√≤ng l·∫∑p (Epochs)
EPOCHS = 10

MODEL_PATH = 'models/digit_model.h5'

# --- KI·ªÇM TRA & C·∫§U H√åNH GPU ---
print("\n" + "="*40)
print("üîç ƒêANG KI·ªÇM TRA PH·∫¶N C·ª®NG...")
gpus = tf.config.list_physical_devices('GPU')
if gpus:
    print(f"‚úÖ ƒê√£ ph√°t hi·ªán {len(gpus)} GPU: {gpus}")
    try:
        # C·∫•u h√¨nh ƒë·ªÉ GPU kh√¥ng b·ªã chi·∫øm d·ª•ng 100% b·ªô nh·ªõ ngay l·∫≠p t·ª©c
        for gpu in gpus:
            tf.config.experimental.set_memory_growth(gpu, True)
        print("üöÄ ƒê√£ k√≠ch ho·∫°t ch·∫ø ƒë·ªô t·ªëi ∆∞u b·ªô nh·ªõ GPU!")
    except RuntimeError as e:
        print(e)
else:
    print("‚ö†Ô∏è Kh√¥ng t√¨m th·∫•y GPU. Code s·∫Ω ch·∫°y b·∫±ng CPU (ch·∫≠m h∆°n).")
print("="*40 + "\n")


# --- X√ÇY D·ª∞NG M√î H√åNH ---
def build_lenet5():
    print("üõ†Ô∏è ƒêang x√¢y d·ª±ng m√¥ h√¨nh LeNet-5...")
    model = models.Sequential([
        layers.Input(shape=(32, 32, 1)),
        layers.Conv2D(6, (5, 5), activation='tanh'),
        layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)),
        layers.Conv2D(16, (5, 5), activation='tanh'),
        layers.AveragePooling2D(pool_size=(2, 2), strides=(2, 2)),
        layers.Flatten(),
        layers.Dense(120, activation='tanh'),
        layers.Dense(84, activation='tanh'),
        layers.Dense(10, activation='softmax')
    ])
    return model

# --- MAIN ---
if __name__ == "__main__":
    # 1. Load d·ªØ li·ªáu
    loader = DidaLoader(data_path=DATASET_PATH, max_images=MAX_IMAGES)
    (x_train, y_train), (x_test, y_test) = loader.load()

    # 2. Kh·ªüi t·∫°o m√¥ h√¨nh
    model = build_lenet5()
    model.compile(optimizer='adam', 
                  loss='sparse_categorical_crossentropy', 
                  metrics=['accuracy'])

    # 3. Hu·∫•n luy·ªán (ƒê√£ th√™m batch_size)
    print(f"üöÄ B·∫Øt ƒë·∫ßu hu·∫•n luy·ªán v·ªõi Batch Size = {BATCH_SIZE}...")
    
    model.fit(
        x_train, y_train, 
        epochs=EPOCHS, 
        batch_size=BATCH_SIZE,  # <--- TƒÉng t·ªëc ƒë·ªô trainS
        validation_data=(x_test, y_test)
    )

    # 4. L∆∞u k·∫øt qu·∫£
    if not os.path.exists('models'):
        os.makedirs('models')
    model.save(MODEL_PATH)
    print(f"\nüéâ HO√ÄN TH√ÄNH! M√¥ h√¨nh ƒë√£ l∆∞u t·∫°i: {MODEL_PATH}")
